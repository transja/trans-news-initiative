data %>%
filter(SegID %in% flagged_segments) %>%
View()
data.flagged <- data %>%
filter(SegID %in% flagged_segments)
data.flagged %>%
group_by(use) %>%
summarise(
count = n()
) %>%
arrange(desc(count))
library(readr)
FimaNfipClaims <- read_csv("Downloads/FimaNfipClaims.csv")
View(FimaNfipClaims)
colnames(FimaNfipClaims)
FimaNfipClaims %>%
FimaNfipClaims %>%
select(buildingDamageAmount,
contentsDamageAmount,
netBuildingPaymentAmount
netContentsPaymentAmount
FimaNfipClaims %>%
select(buildingDamageAmount,
contentsDamageAmount,
netBuildingPaymentAmount,
netContentsPaymentAmount
)
library(readr)
FimaNfipClaims %>%
select(buildingDamageAmount,
contentsDamageAmount,
netBuildingPaymentAmount,
netContentsPaymentAmount
)
library(dplyr)
FimaNfipClaims %>%
select(buildingDamageAmount,
contentsDamageAmount,
netBuildingPaymentAmount,
netContentsPaymentAmount
)
library(readr)
library(dplyr)
nodes <- read_csv("Documents/github/polygraph/2025/trans-news-initiative/src/data/articles_with_themes.csv")
devtools::install_github("andrewbtran/muckrakr")
#install.packages("devtools")
devtools::install_github("andrewbtran/muckrakr")
install.packages("devtools")
# install.packages("devtools")
devtools::install_github("andrewbtran/muckrakr")
combined <- bulk_csv(folder = "Documents/github/polygraph/2025/trans-journalism-initiative-data/output/articles/")
# install.packages("devtools")
devtools::install_github("andrewbtran/muckrakr")
?bulk_csv
andrewbtran/muckrakr::bulk_csv()
combined <- andrewbtran/muckrakr::bulk_csv(folder = "Documents/github/polygraph/2025/trans-journalism-initiative-data/output/articles/")
andrewbtran
muckrakr
combined <- muckrakr::bulk_csv(folder = "Documents/github/polygraph/2025/trans-journalism-initiative-data/output/articles/")
View(combined)
colnames(combined)
combined %>%
select(title, publish_date, media_name, url)
combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste0(title,publish_date)
)
combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste0(publish_date,gsub(" ","-", tolower(title)))
)
combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste0(publish_date,gsub(" ","-", tolower(title)))
) %>%  View()
combined <- combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste(publish_date,gsub(" ","-", tolower(title), sep="-"))
)
View(combined)
combined <- muckrakr::bulk_csv(folder = "Documents/github/polygraph/2025/trans-journalism-initiative-data/output/articles/")
combined <- combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste(publish_date,gsub(" ","-", tolower(title), sep="-"))
)
?paste
combined <- combined %>%
select(title, publish_date, media_name, url) %>%
mutate(
joiner = paste(publish_date,gsub(" ","-", tolower(title)), sep="-")
)
View(combined)
nodes
for (i in 1:nrow(Data_Clean)) {
temp_new_participant <- Data_Clean[i, duty_cols]
predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
}
#Set up packages
library(tidyverse)
library(tidyr)
library(ppcor)
library(reshape2)
library(rlang)
library(vegan)
library(factoextra)
library(dplyr)
select <- dplyr::select
#Import Data
Data_Raw <- read.csv("CR_Data_Names.csv")
Data_Clean <- Data_Raw %>%
mutate(pid3 = trimws(pid3))  # Remove leading & trailing spaces
# Rename duties_full_list_X to duties_X
names(Data_Clean) <- gsub("^duties_full_list_", "duties_", names(Data_Clean))
# Select just the civic duty columns
duty_vars <- grep("^duties_\\d+$", names(Data_Clean), value = TRUE)
# Recode all duty items as 1 (Civic obligation) and 0 (Not a civic obligation)
Data_Clean <- Data_Clean %>%
mutate(across(all_of(duty_vars), ~ case_when(
.x == "Civic responsibility" ~ 1,
.x == "Not a civic responsibility" ~ 0,
TRUE ~ NA_real_
)))
# First, create a named vector with the descriptive labels
temp <- c(
"Voting",
"Obeying the law",
"Paying your taxes",
"Reporting for jury duty",
"Staying informed of current events",
"Doing community service",
"Respecting people's differences",
"Protecting the environment",
"Caring for future generations",
"Following the Constitution",
"Being patriotic",
"Working hard",
"Making your voice heard",
"Fighting for people’s rights",
"Supporting your family",
"Supporting democracy",
"Protesting unfairness",
"Donating to charity",
"Defending freedom",
"Practicing freedom of speech",
"Helping your community",
"Joining the military",
"Supporting equality",
"Loving America",
"Making the most of your opportunities",
"Connecting across differences",
"Being grateful for your opportunities as an American",
"Honoring the flag",
"Welcoming refugees",
"Being self-reliant"
)
# Assign names matching your plotting variable names
names(temp) <- paste0("duties_", 1:30)
Data_Clean <- Data_Clean %>%
mutate(urban_binary = case_when(
urban == "Urban" ~ "Urban",
urban %in% c("Suburban", "Rural") ~ "Suburban/Rural",
TRUE ~ NA_character_
))
Data_Clean <- Data_Clean %>%
mutate(ideology_tri = case_when(
ideology %in% c("Liberal", "Slightly liberal", "Very liberal") ~ "Liberal",
ideology %in% c("Moderate") ~ "Moderate",
ideology %in% c("Conservative", "Slightly conservative", "Very conservative") ~ "Conservative",
TRUE ~ NA_character_
))
Data_Clean <- Data_Clean %>%
mutate(age_binary = case_when(
age > 50 ~ "old",
age <= 50 ~ "young",
TRUE ~ NA_character_
))
predict_groups <- function(new_data_row, df, duty_cols, group_vars) {
predictions <- list()
for (group_var in group_vars) {
# Compute weighted prototypes for each group
prototype_df <- df %>%
filter(!is.na(.data[[group_var]])) %>%
group_by(.data[[group_var]]) %>%
summarise(across(all_of(duty_cols), ~ weighted.mean(.x, w = Weight, na.rm = TRUE)), .groups = "drop") %>%
rename(group = !!group_var)
# Compute Manhattan distance to each group prototype
distances <- prototype_df %>%
rowwise() %>%
mutate(dist = sum(abs(c_across(all_of(duty_cols)) - new_data_row))) %>%
ungroup()
# Identify the closest group
predicted_group <- distances$group[which.min(distances$dist)]
predictions[[group_var]] <- predicted_group
}
return(predictions)
}
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[1, duty_cols]
for (i in 1:nrow(Data_Clean)) {
temp_new_participant <- Data_Clean[i, duty_cols]
predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
}
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[1, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
Predict
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[1, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[2, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[1, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
predict_groups <- function(new_data_row, df, duty_cols, group_vars) {
predictions <- list()
for (group_var in group_vars) {
# Compute weighted prototypes for each group
prototype_df <- df %>%
filter(!is.na(.data[[group_var]])) %>%
group_by(.data[[group_var]]) %>%
summarise(across(all_of(duty_cols), ~ weighted.mean(.x, w = Weight, na.rm = TRUE)), .groups = "drop") %>%
rename(group = !!group_var)
# Compute Manhattan distance to each group prototype
distances <- prototype_df %>%
rowwise() %>%
mutate(dist = sum(abs(c_across(all_of(duty_cols)) - new_data_row))) %>%
ungroup()
print(distances)
# Identify the closest group
predicted_group <- distances$group[which.min(distances$dist)]
predictions[[group_var]] <- predicted_group
}
return(predictions)
}
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[1, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[2, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[3, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[10, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[5, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
# Define variables
duty_cols <- paste0("duties_", 1:30)
group_vars <- c("urban_binary", "ideology_tri", "age_binary")
# Example: Test out with the first row from existing dataset
new_participant <- Data_Clean[4, duty_cols]
# for (i in 1:nrow(Data_Clean)) {
#   temp_new_participant <- Data_Clean[i, duty_cols]
#   predicted_categories <- predict_groups(temp_new_participant, Data_Clean, duty_cols, group_vars)
#   print(predicted_categories)
# }
#
# Predict
predicted_categories <- predict_groups(new_participant, Data_Clean, duty_cols, group_vars)
print(predicted_categories)
setwd("~/Documents/github/polygraph/2025/trans-news-initiative/admin")
process_themes <- function(input_csv, output_dir = "themes_json") {
# Read CSV
df <- read_csv(input_csv, show_col_types = FALSE)
# Ensure output directory exists
dir_create(output_dir)
# Split comma-separated themes only for grouping
df_grouped <- df %>%
mutate(theme_split = strsplit(themes, "\\s*,\\s*")) %>%
unnest(theme_split) %>%
mutate(theme_split = trimws(theme_split)) %>%
filter(theme_split != "")
# Group by each individual theme and write out JSON of full original rows
df_grouped %>%
group_split(theme_split) %>%
walk(function(group_data) {
theme_name <- unique(group_data$theme_split)
file_name <- paste0(output_dir, "/", gsub("[^a-zA-Z0-9_-]", "_", theme_name), ".json")
# Keep the original CSV 'themes' string in the JSON output
json <- toJSON(select(group_data, -theme_split), pretty = FALSE, auto_unbox = TRUE)
write_lines(json, file_name)
})
}
process_themes("all_data_tji_tags_threshold_0_85.csv", "out_json")
library(dplyr)
library(tidyr)
library(jsonlite)
library(readr)
library(fs)
library(purrr)
library(dplyr)
library(tidyr)
library(jsonlite)
library(readr)
library(fs)
library(purrr)
process_themes <- function(input_csv, output_dir = "themes_json") {
# Read CSV
df <- read_csv(input_csv, show_col_types = FALSE)
# Ensure output directory exists
dir_create(output_dir)
# Split comma-separated themes only for grouping
df_grouped <- df %>%
mutate(theme_split = strsplit(themes, "\\s*,\\s*")) %>%
unnest(theme_split) %>%
mutate(theme_split = trimws(theme_split)) %>%
filter(theme_split != "")
# Group by each individual theme and write out JSON of full original rows
df_grouped %>%
group_split(theme_split) %>%
walk(function(group_data) {
theme_name <- unique(group_data$theme_split)
file_name <- paste0(output_dir, "/", gsub("[^a-zA-Z0-9_-]", "_", theme_name), ".json")
# Keep the original CSV 'themes' string in the JSON output
json <- toJSON(select(group_data, -theme_split), pretty = FALSE, auto_unbox = TRUE)
write_lines(json, file_name)
})
}
process_themes("all_data_tji_tags_threshold_0_85.csv", "out_json")
#######################################################################################
#######################################################################################
library(dplyr)
library(tidyr)
library(readr)
library(lubridate)
library(stringr)
library(jsonlite)
library(fs)
# helper for safely coalescing NULL to ""
`%||%` <- function(a, b) if (is.null(a)) b else a
make_monthly_file <- function(input_csv, output_file = "monthly.json") {
df <- read_csv(input_csv, show_col_types = FALSE)
# Parse publish_date (handles 'YYYY-MM-DD...' and 'MM/DD/YY')
pub_iso <- suppressWarnings(ymd(str_sub(df$publish_date %||% "", 1, 10)))
pub_mdy <- suppressWarnings(mdy(df$publish_date %||% ""))
df <- df %>%
mutate(publish_date = coalesce(pub_iso, pub_mdy)) %>%
filter(!is.na(publish_date))
# Explode comma-separated themes, trim, drop empties
df_expanded <- df %>%
mutate(themes = str_split(coalesce(themes, ""), "\\s*,\\s*")) %>%
unnest(themes) %>%
mutate(theme = str_trim(themes)) %>%
filter(theme != "") %>%
select(-themes) %>%
mutate(month = floor_date(publish_date, "month"))
if (nrow(df_expanded) == 0) {
dir_create(path_dir(output_file))
write_lines("[]", output_file)
return(invisible(tibble()))
}
# Counts per (month, theme) – distinct pid if present, else row count
has_pid <- "pid" %in% names(df_expanded)
counts <- if (has_pid) {
df_expanded %>%
group_by(month, theme) %>%
summarise(count = n_distinct(pid), .groups = "drop")
} else {
df_expanded %>%
group_by(month, theme) %>%
summarise(count = dplyr::n(), .groups = "drop")
}
# Zero-fill full grid (months x themes)
months_seq <- seq.Date(floor_date(min(df_expanded$publish_date), "month"),
floor_date(max(df_expanded$publish_date), "month"),
by = "month")
theme_set <- sort(unique(df_expanded$theme))
full_grid <- crossing(month = months_seq, theme = theme_set) %>%
left_join(counts, by = c("month", "theme")) %>%
mutate(count = replace_na(count, 0L)) %>%
arrange(month, theme)
# Write minified JSON
out <- full_grid %>%
mutate(month = as.character(month)) %>%
select(month, theme, count)
dir_create(path_dir(output_file))
write_lines(toJSON(out, pretty = FALSE, auto_unbox = TRUE), output_file)
invisible(out)
}
make_monthly_file("all_data_jd_tags_threshold_0_85.csv", "out_json/monthly.json")
make_monthly_file("all_data_tji_tags_threshold_0_85", "out_json/monthly.json")
make_monthly_file("all_data_tji_tags_threshold_0_85.csv", "out_json/monthly.json")
count_articles("all_data_tji_tags_threshold_0_85.csv", "out_json/article_count.json")
library(readr)
library(jsonlite)
library(fs)
count_articles <- function(input_csv, output_file = "article_count.json") {
# Read CSV
df <- read_csv(input_csv, show_col_types = FALSE)
df < filter(df, length(themes) > 0)
# Count total rows (articles)
count <- nrow(df)
# Prepare JSON object
out <- list(total_articles = count)
# Ensure output directory exists
dir_create(path_dir(output_file))
# Write minified JSON
write_lines(toJSON(out, pretty = FALSE, auto_unbox = TRUE), output_file)
invisible(out)
}
count_articles("all_data_tji_tags_threshold_0_85.csv", "out_json/article_count.json")
